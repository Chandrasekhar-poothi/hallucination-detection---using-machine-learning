{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOoOg5d0h+ObPOBRbAc/Sdq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"uaX9DItAblHO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708071839365,"user_tz":-330,"elapsed":10652,"user":{"displayName":"Chandra Sekhar","userId":"11626649543123042561"}},"outputId":"5980344c-43d6-4521-e9b5-b27374288bab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the path to the CSV file: /content/Hallucination-Dataset-400-Samples.csv\n","Accuracy: 0.8518518518518519\n","F1 Score: 0.890909090909091\n","Updated CSV file saved as: /content/Hallucination-Dataset-400-Samples_updated.csv\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import LinearSVC\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","def train_hallucination_detector(input_csv):\n","    # Read the CSV file\n","    data = pd.read_csv(input_csv)\n","\n","    # Handling missing values\n","    data = data.fillna('')\n","\n","    # Preprocessing\n","    X_context = data['Context']\n","    X_question = data['Question']\n","    X_answer = data['Answer']\n","    y = data['Hallucination']\n","\n","    # Split the dataset into training and testing sets\n","    X_context_train, X_context_test, \\\n","    X_question_train, X_question_test, \\\n","    X_answer_train, X_answer_test, \\\n","    y_train, y_test = train_test_split(X_context, X_question, X_answer, y, test_size=0.2, random_state=42)\n","\n","    # Define the pipeline for each text column separately\n","    clf_context = Pipeline([\n","        ('tfidf', TfidfVectorizer()),\n","        ('svm', LinearSVC())\n","    ])\n","    clf_question = Pipeline([\n","        ('tfidf', TfidfVectorizer()),\n","        ('svm', LinearSVC())\n","    ])\n","    clf_answer = Pipeline([\n","        ('tfidf', TfidfVectorizer()),\n","        ('svm', LinearSVC())\n","    ])\n","\n","    # Train the models\n","    clf_context.fit(X_context_train, y_train)\n","    clf_question.fit(X_question_train, y_train)\n","    clf_answer.fit(X_answer_train, y_train)\n","\n","    # Make predictions on the test sets\n","    y_pred_context = clf_context.predict(X_context_test)\n","    y_pred_question = clf_question.predict(X_question_test)\n","    y_pred_answer = clf_answer.predict(X_answer_test)\n","\n","    # Combine the predictions from each model using simple voting\n","    y_pred_combined = (y_pred_context + y_pred_question + y_pred_answer) >= 2\n","\n","    # Evaluate accuracy\n","    accuracy = accuracy_score(y_test, y_pred_combined)\n","    print(\"Accuracy:\", accuracy)\n","\n","    # Compute F1 score\n","    f1 = f1_score(y_test, y_pred_combined)\n","    print(\"F1 Score:\", f1)\n","\n","    # Make predictions on the entire dataset\n","    all_predictions_context = clf_context.predict(X_context)\n","    all_predictions_question = clf_question.predict(X_question)\n","    all_predictions_answer = clf_answer.predict(X_answer)\n","\n","    # Combine the predictions from each model for the entire dataset\n","    all_predictions_combined = (all_predictions_context + all_predictions_question + all_predictions_answer) >= 2\n","\n","    # Update the 'Prediction' column with the model's predictions\n","    data['Prediction'] = all_predictions_combined.astype(int)\n","\n","    # Save the updated DataFrame to a new CSV file\n","    output_csv = input_csv.split('.')[0] + '_updated.csv'\n","    data.to_csv(output_csv, index=False)\n","\n","    print(\"Updated CSV file saved as:\", output_csv)\n","\n","input_csv = input(\"Enter the path to the CSV file: \")\n","train_hallucination_detector(input_csv)"]},{"cell_type":"code","source":[],"metadata":{"id":"duh5b9LgkPc-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AECqlri4kQcz"},"execution_count":null,"outputs":[]}]}